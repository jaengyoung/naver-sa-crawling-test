## í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (Core Business Logic)

### ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

ì´ ë„¤ì´ë²„ ê²€ìƒ‰ í¬ë¡¤ëŸ¬ëŠ” AWS Lambda í™˜ê²½ì—ì„œ ì‹¤í–‰ë˜ë©°, SQS íë¡œë¶€í„° í‚¤ì›Œë“œë¥¼ ë°›ì•„ ë°ìŠ¤í¬í†±/ëª¨ë°”ì¼ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ê³  S3ì— ì €ì¥í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```
[SQS Queue] â†’ [Lambda Function] â†’ [Naver Search] â†’ [S3 Storage]
     â†“              â†“                    â†“              â†“
  í‚¤ì›Œë“œ ë©”ì‹œì§€    í¬ë¡¤ë§ ì‹¤í–‰        ê²€ìƒ‰ê²°ê³¼ ì¶”ì¶œ    CSV íŒŒì¼ ì €ì¥
```

### ì£¼ìš” êµ¬ì„± ìš”ì†Œ ë° ì²˜ë¦¬ íë¦„

#### 1. ë©”ì‹œì§€ ì²˜ë¦¬ (`message_processor.go`)

SQSì—ì„œ ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ê³  ë³‘ë ¬ ì²˜ë¦¬í•©ë‹ˆë‹¤:

```go
package main

import (
    "log"
    "sync"
    "lambda/internal"
)

func main() {
    // SQSì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ 
    messages, err := internal.ReceiveMessages()
    if err != nil {
        log.Fatal("ë©”ì‹œì§€ ìˆ˜ì‹  ì‹¤íŒ¨:", err)
    }
    
    // ë™ì‹œ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê³ ë£¨í‹´ í’€
    var wg sync.WaitGroup
    sem := make(chan struct{}, 10) // ìµœëŒ€ 10ê°œ ë™ì‹œ ì²˜ë¦¬
    
    for _, message := range messages {
        wg.Add(1)
        sem <- struct{}{} // ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„± ì œì–´
        
        go func(msg *sqs.Message) {
            defer wg.Done()
            defer func() { <-sem }()
            
            // ê° í‚¤ì›Œë“œì— ëŒ€í•´ í¬ë¡¤ë§ ì‹¤í–‰
            internal.ProcessMessage(msg, &wg, sem)
        }(message)
    }
    
    wg.Wait()
    log.Println("ëª¨ë“  í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ")
}
```

#### 2. í¬ë¡¤ë§ ë¡œì§ (`desktop_scraper.go`, `mobile_scraper.go`)

ê° ë””ë°”ì´ìŠ¤ë³„ë¡œ ìµœì í™”ëœ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

```go
package main

import (
    "encoding/json"
    "fmt"
    "log"
    "lambda/internal"
)

func í¬ë¡¤ë§_ì˜ˆì œ() {
    keyword := "ìŠ¤ë§ˆíŠ¸í°"
    
    // ë°ìŠ¤í¬í†± í¬ë¡¤ë§
    fmt.Println("ğŸ–¥ï¸ ë°ìŠ¤í¬í†± í¬ë¡¤ë§ ì‹œì‘...")
    desktopResults, err := internal.ScrapeDesktopResultsWithDebug(keyword)
    if err != nil {
        log.Printf("ë°ìŠ¤í¬í†± í¬ë¡¤ë§ ì‹¤íŒ¨: %v", err)
    }
    
    // ëª¨ë°”ì¼ í¬ë¡¤ë§  
    fmt.Println("ğŸ“± ëª¨ë°”ì¼ í¬ë¡¤ë§ ì‹œì‘...")
    mobileResults, err := internal.ScrapeMobileResultsWithDebug(keyword)
    if err != nil {
        log.Printf("ëª¨ë°”ì¼ í¬ë¡¤ë§ ì‹¤íŒ¨: %v", err)
    }
    
    // ê²°ê³¼ í†µí•© ë° ì¶œë ¥
    allResults := append(desktopResults, mobileResults...)
    
    fmt.Printf("ğŸ“Š í¬ë¡¤ë§ ì™„ë£Œ: ì´ %dê°œ ê²°ê³¼\n", len(allResults))
    fmt.Printf("  - ë°ìŠ¤í¬í†±: %dê°œ\n", len(desktopResults))
    fmt.Printf("  - ëª¨ë°”ì¼: %dê°œ\n", len(mobileResults))
    
    // JSON í˜•íƒœë¡œ ì¶œë ¥
    jsonData, _ := json.MarshalIndent(allResults, "", "  ")
    fmt.Println(string(jsonData))
}
```

#### 3. ë°ì´í„° ì—…ë¡œë“œ (`result_uploader.go`)

í¬ë¡¤ë§ ê²°ê³¼ë¥¼ CSV í˜•íƒœë¡œ ì••ì¶•í•˜ì—¬ S3ì— ì €ì¥í•©ë‹ˆë‹¤:

```go
// ì‹¤ì œ ì—…ë¡œë“œ í”„ë¡œì„¸ìŠ¤ ì˜ˆì œ
func ì—…ë¡œë“œ_ì˜ˆì œ() {
    results := []internal.SearchResult{
        {
            Query:       "ìŠ¤ë§ˆíŠ¸í°",
            Device:      "Mobile", 
            Rank:        1,
            SiteName:    "ë””ë² ì´",
            DisplayURL:  "dbay.io",
            Title:       "ê²¬ì ë¹„êµ í”Œë«í¼ ë””ë² ì´",
            Description: "700ëª… ë”œëŸ¬ë“¤ì˜ í˜œíƒê²½ìŸìœ¼ë¡œ ê°€ê²©ì€ DOWN í˜œíƒì€ UP!",
        },
        // ... ë” ë§ì€ ê²°ê³¼ë“¤
    }
    
    // S3 ì—…ë¡œë“œ (ë‚´ë¶€ì ìœ¼ë¡œ CSV ë³€í™˜ ë° GZIP ì••ì¶• ìˆ˜í–‰)
    // íŒŒì¼ ê²½ë¡œ: s3://bucket/data/basic_date=20250811/hh=14/uuid.csv.gz
    internal.UploadResult(results, "ìŠ¤ë§ˆíŠ¸í°")
}
```

### íƒì§€ íšŒí”¼ ë©”ì»¤ë‹ˆì¦˜

#### 1. ëœë¤ í—¤ë” ìƒì„± (`http_client.go`)

```go
func í—¤ë”_ì˜ˆì œ() {
    // ë§¤ ìš”ì²­ë§ˆë‹¤ ë‹¤ë¥¸ í—¤ë” ì¡°í•© ìƒì„±
    headers := internal.GenerateRandomHeaders()
    
    fmt.Println("ìƒì„±ëœ í—¤ë”:")
    for key, value := range headers {
        fmt.Printf("  %s: %s\n", key, value)
    }
    
    // ì¶œë ¥ ì˜ˆì‹œ:
    // User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...
    // Referer: https://www.naver.com/
    // Accept-Language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7
    // Origin: https://search.naver.com (50% í™•ë¥ ë¡œ ì¶”ê°€)
    // Cookie: NID=abc123; NNB=xyz456 (30% í™•ë¥ ë¡œ ì¶”ê°€)
}
```

#### 2. CSS ì…€ë ‰í„° ìµœì í™”

ê° í”Œë«í¼ë³„ë¡œ íŠ¹í™”ëœ ì…€ë ‰í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

```go
// ë°ìŠ¤í¬í†±ìš© ì…€ë ‰í„°
const (
    desktopResultSelector = "div.nad_area ul.lst_type > li"
    desktopTitleSelector  = "a.lnk_head span.lnk_tit"  
    desktopSiteSelector   = "a.site"
    desktopURLSelector    = "span.lnk_url_area > a.lnk_url"
    desktopDescSelector   = "a.link_desc"
)

// ëª¨ë°”ì¼ìš© ì…€ë ‰í„° 
const (
    mobileResultSelector = "div.api_subject_bx ul.lst_total > li"
    mobileTitleSelector  = "div.tit_area span.tit"
    mobileSiteSelector   = "span.site" 
    mobileURLSelector    = "span.url"
    mobileDescSelector   = "a.desc"
)
```

### ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ë‹¨ì¼ í‚¤ì›Œë“œ í¬ë¡¤ë§

```go
func ë‹¨ì¼_í‚¤ì›Œë“œ_í¬ë¡¤ë§() {
    keyword := "ê°¤ëŸ­ì‹œS25"
    
    // ëª¨ë°”ì¼ ìš°ì„  í¬ë¡¤ë§ (ì¼ë°˜ì ìœ¼ë¡œ ë” ì•ˆì •ì )
    results, err := internal.ScrapeMobileResults(keyword)
    if err != nil {
        log.Printf("ëª¨ë°”ì¼ í¬ë¡¤ë§ ì‹¤íŒ¨: %v", err)
        return
    }
    
    fmt.Printf("'%s' ê²€ìƒ‰ê²°ê³¼ %dê°œ ìˆ˜ì§‘ ì™„ë£Œ\n", keyword, len(results))
    
    // ê° ê²°ê³¼ ì¶œë ¥
    for i, result := range results {
        fmt.Printf("%d. [%s] %s - %s\n", 
            result.Rank, result.SiteName, result.Title, result.DisplayURL)
    }
}
```

#### ì‹œë‚˜ë¦¬ì˜¤ 2: ë°°ì¹˜ ì²˜ë¦¬

```go
func ë°°ì¹˜_ì²˜ë¦¬_ì˜ˆì œ() {
    keywords := []string{"ê°¤ëŸ­ì‹œS25", "ì•„ì´í°16", "í”½ì…€9"}
    
    var allResults []internal.SearchResult
    
    for _, keyword := range keywords {
        fmt.Printf("ğŸ” '%s' í¬ë¡¤ë§ ì¤‘...\n", keyword)
        
        // ë°ìŠ¤í¬í†±ê³¼ ëª¨ë°”ì¼ ë™ì‹œ ì²˜ë¦¬
        var wg sync.WaitGroup
        var desktopResults, mobileResults []internal.SearchResult
        
        wg.Add(2)
        
        // ë°ìŠ¤í¬í†± í¬ë¡¤ë§ ê³ ë£¨í‹´
        go func() {
            defer wg.Done()
            results, err := internal.ScrapeDesktopResults(keyword)
            if err == nil {
                desktopResults = results
            }
        }()
        
        // ëª¨ë°”ì¼ í¬ë¡¤ë§ ê³ ë£¨í‹´  
        go func() {
            defer wg.Done()
            results, err := internal.ScrapeMobileResults(keyword)
            if err == nil {
                mobileResults = results
            }
        }()
        
        wg.Wait()
        
        // ê²°ê³¼ í•©ì¹˜ê¸°
        allResults = append(allResults, desktopResults...)
        allResults = append(allResults, mobileResults...)
        
        fmt.Printf("âœ… '%s' ì™„ë£Œ: ë°ìŠ¤í¬í†± %dê°œ, ëª¨ë°”ì¼ %dê°œ\n", 
            keyword, len(desktopResults), len(mobileResults))
    }
    
    fmt.Printf("ğŸ‰ ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ì´ %dê°œ ê²°ê³¼\n", len(allResults))
}
```

### ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬

```go
func ì•ˆì •ì ì¸_í¬ë¡¤ë§() {
    keyword := "ìŠ¤ë§ˆíŠ¸í°"
    maxRetries := 3
    
    for i := 0; i < maxRetries; i++ {
        results, err := internal.ScrapeMobileResults(keyword)
        if err == nil {
            fmt.Printf("âœ… í¬ë¡¤ë§ ì„±ê³µ: %dê°œ ê²°ê³¼\n", len(results))
            return
        }
        
        fmt.Printf("âš ï¸ ì‹œë„ %d/%d ì‹¤íŒ¨: %v\n", i+1, maxRetries, err)
        
        if i < maxRetries-1 {
            // ì¬ì‹œë„ ì „ ëŒ€ê¸° (ë°±ì˜¤í”„ íŒ¨í„´)
            time.Sleep(time.Duration(i+1) * time.Second)
        }
    }
    
    fmt.Println("âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨")
}
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ê°œë°œ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸
cd source/lambda

# ë°ìŠ¤í¬í†± í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
go run test_desktop.go -keyword="ê°¤ëŸ­ì‹œS25"

# ëª¨ë°”ì¼ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸  
go run test_mobile.go -keyword="ê°¤ëŸ­ì‹œS25"

# ì‹¤ì œ Lambda í™˜ê²½ ë°°í¬ í›„
# SQSì— ë©”ì‹œì§€ ì „ì†¡í•˜ë©´ ìë™ìœ¼ë¡œ í¬ë¡¤ë§ ì‹¤í–‰ ë° S3 ì—…ë¡œë“œ ìˆ˜í–‰
```

ì´ ì‹œìŠ¤í…œì€ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ì—¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ë‚˜ ë§ˆì¼€íŒ… ë¶„ì„ì— í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## License

This project is for educational and research purposes. Please ensure compliance with Naver's robots.txt and terms of service when using this crawler.